---
layout: post
title: python爬虫之--静态网站和动态网站的爬取
date: 2020-1-18
categories: blog
tags: [python爬虫]
description: 语言
---

### 简述一下今天的小激动
<p style="color: red">哈哈哈，今天着实开心，踩着年关完成了我一直想完成的一件事-----就是给我博客加上评论系统。创建这个博客以来，我一直觉得很遗憾的就是没有评论板块，今天完成了，也算是完成了我的一件心事。还有就是终于不用“偷偷摸摸写爬虫了”，终于把破解版永久pycharm给搞到了，想不到原来就是把一个文件放错位置才导致失败，哈哈哈</p>


## 静态网页的爬取
### requests
requests库是个功能强大的库对象。通过内置get('url')可以得到网页的html信息。
      
     r=requests.get(link,headers=header)
     print(r.text)

上述代码中，link是目标网页的地址，header为伪浏览器，也叫做请求头。<br>
#### 请求头做法
打开目标网页，通过审查元素打开网页操作台，然后点击network,按F5刷新，点击有一个网址的文件，看右下角有一个'user-angent',这个就是请求头，一般的右下角还有'host：'这个选项，一般都要加上。但它一般都是主网址。
![python](/img/python2.png)

#### 状态响应码
即r.statue_code。<br>
详细可看这篇博客。<https://blog.csdn.net/ddhsea/article/details/79405996>

#### 网页解析--beautifulsoup
通过上面的代码得到的是整个网页的信息，而我梦要提取我们想要的，所以要用到beautifulsoup,这个库我还没有了解，所知也甚微，但这句就是转换为beautifusoup类型的语句

    soup=beautifulsoup(r.text,"lxml")
然后用beautiful库自带的操作查找我们想要的标签，比如'div','p'等等

#### 实例
爬取一个豆瓣的最近电影前top100<br>
按照上述的准备好之后就去原网站去看我们想要的div或着p标签了。为了简单我就爬一个页面叭（狗头.jpg)。代码也比较简单

    #!/usr/bin/env python
    # -*-coding:utf-8-*-
    import requests
    from bs4 import BeautifulSoup
    import re
    header={
    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36',
    'Host':'movie.douban.com'
    }
    movie_list=[]
    link='https://movie.douban.com/chart'
    r=requests.get(link,headers=header,timeout=10)
    print('状态响应码为',r.status_code)
    #print(r.text)
    soup=BeautifulSoup(r.text,"lxml")
    div_list=soup.find_all('div',class_='pl2')
    for i in div_list:
    	movie=i.a.text.strip()#a标签下的span标签,strip为字符串分割
    	movie_list.append(movie)
    for i in range(0,len(movie_list)):
    	print(movie_list[i])


结果
![python](/img/python3.png)

## 动态网页的爬取











