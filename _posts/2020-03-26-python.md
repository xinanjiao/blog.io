---
layout: post
title: python爬取京东华为荣耀手机500条评论，然后做成词云分析频繁词
date: 2020-03-26
categories: blog
tags: [python爬虫]
description: 文章金句。
---
参考网址：<https://blog.csdn.net/u014044812/article/details/95198791>
### 为什么我要写这个爬虫
在b站学习python爬虫慕课的时候，有一个实例就是爬取淘宝的商品，然后那时候老师的视频是17年录的，那时候淘宝的反爬机制没有那么严格。而现在自动登陆贼麻烦，我在网上看淘宝登陆的时候看见了京东的这个爬虫，京东相比来说比较好爬，我就跟着教程学习了。有一说一，python的库可真好用。

### 准备工作
1. 进入京东的页面，开启控制台打开network获取json格式的评论文件。
2. 直接爬取该json文件的url，发现并没有结果，打开控制台复制一下请求头继续操作。
3. 多页爬取，将评论存在txt文件里。
4. 运用jieba库，进行分词
5. 运用wordcloud库生成词云


### 注意
json文件的操作需要运用python内置的json解析库。

爬取的时候，注意京东是'GBK'编码，然后写入文件是要加上encoding='utf-8'。爬取的时候为了防止频率过快而被封ip，加上睡眠时间time.sleep(random.random() * 5)

取分词的时候，注意要去掉中文的符号以及数字和字母

制作词云的时候，打开图片要用Image.open('XXX')

## 各个板块

### 爬取评论
取得评论内容：因为是动态页面，爬取动态页面的数据有两个办法：第一个是找到json文件加以解析，第二个是用selnium模拟浏览器操作。我这里用前者。
```
def getcomments():#获得评论
	#os是一个检查文件等输入输出的库
    if os.path.exists(root):  # 如果存在就清空
        os.remove(root)
    try:

        for j in range(0, 50):
            link = str1 + linkadd(j) + str2 #找到规律然后添加上
            # print(link)
            r = requests.get(link, headers=kv)
            r.raise_for_status()
            r.encoding = r.apparent_encoding
            r_json = r.text[20:-2] #去掉非法格式
            r_string = json.loads(r_json)
            r_comments = r_string['comments']
            for i in r_comments:
                with open(root, 'a+', encoding='utf-8') as f:  # a+覆盖写入
                    f.write(i['content'])
            print('第 %d个评论爬取成功' % j)
            time.sleep(random.random() * 5)
    except:
        print("sorry! crawl fail")
```

### 切割分词
这里用到了jieba库，一个优秀的第三方库，里面很多的参数需要我好好的去学习一下，就是把句子切割为一个个的词语，为做词云做准备。
```
def cutword():#分词
    with open(root,encoding='utf-8') as f:
        comments=f.read()
        #comments = re.sub(r"[0-9\s+\.\!\/_,$%^*()?;；:-【】+\"\']+|[+——！，;：。？、~@#￥%……&*（）]+", "", comments)
        for ch in '!"#$%&()*+,-./:;：，！<=>?@[\\]^_‘？{|}【】￥~0123456789。':#去除非法字符
            comments = comments.replace(ch, " ")
        comments=re.sub('[A-Za-z]','',comments) #去除英文字母
        newstring=jieba.cut(comments,cut_all=True) #全部切割 返回迭代类型
        wl=' '.join(newstring)
        #print(wl)
        return wl

```


### 生成词云
生成词云需要很多第三方库的配合，需要下载：numpy pillow,wordcloud和图像处理的matplotlib。<br>
安装worldcloud库也是一个苦差事，最后Anaconda也没有安装好，还是看了网上的一个通用方法。<br>
```
#制作词云
def creativewordcloud():
    coloring=np.array(Image.open('girl.png'))
    wordpath='simsun.ttc'
    #配置参数
    wc=WordCloud(width=1000,height=700,background_color='white',max_words=2000,mask=coloring,
                 scale=4,max_font_size=50,random_state=42,font_path=wordpath)
    #生成词云
    wc.generate(cutword())
    #生成图片
    plt.imshow(wc,interpolation="bilinear") 
    plt.axis('off')
    plt.figure()
    plt.show()
    wc.to_file('C:\\Users\\92507\\Desktop\\temp.png')
```

### 完整代码及成果
```
#!/usr/bin/env python
# -*-coding:utf-8-*-
# 爬取京东500条关于荣耀手机的评论 做成词云
import requests
from bs4 import BeautifulSoup
import re
import os
import json
import time
import random
import jieba
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from wordcloud import WordCloud
kv = {
    #'cookie' :'shshshfpb=1a5454d19657b4faf8361195896f9b9350452946aa60c7fc85be013c4d; shshshfpa=7d080eee-8b35-a3a3-1153-459163f4b056-1568120315; __guid=143920055.321352504511342400.1576504472741.615; __jdu=15681203160801314717311; areaId=4; ipLoc-djd=4-48204-48213-0; PCSYCityID=CN_0_0_0; user-key=51144762-4cfd-4435-9d0e-c9f9ee4488e9; cn=0; unpl=V2_ZzNtbUZWERUmDERXKBhYVWJQQF1KURMTJVpDVysfDwRnVhsIclRCFnQUR1ZnGlgUZwYZXkFcQhJFCEdkeBBVAWMDE1VGZxpFK0oYEDpBA04%2bR0ICLFYTHHMME1N7S1hSMwYUCEsEERB8D0BcextfDWUAR15AZ3MWdThGVUsZWAJuAxFcQFdEFHwJRlZ7HFoFYQESXXJnRCVFOEVUfhtVAVcCIlxyFRdJcAhOUn0QEQVjBBtdQVZBFXIJT1V7G1wAYQMUX0JXcxRFCw%3d%3d; __jdv=76161171|haosou-pinzhuan|t_288551095_haosoupinzhuan|cpc|0a875d61c5fe47d8bc48679132932d23_0_50c1b532b05a4bc197a7ac42a7b01d8d|1585117326650; xtest=2799.cf6b6759; monitor_count=1; __jda=122270672.15681203160801314717311.1568120316.1584709830.1585117327.11; __jdb=122270672.2.15681203160801314717311|11.1585117327; __jdc=122270672; shshshfp=1b01c1552c31c967ba5ee34fb63550eb; shshshsID=95bfcd4fa1dccb7c535d35aa4b64d832_2_1585117335366; qrsc=2; rkv=V0600; 3AB9D23F7A4B3C9B=6EMQSIEJ3FMB7ZTJ6IUHFQU2EP2QIO4Y5QUUN5L7JTPNR5QQZBILH4EC2WWS5HEYUZGNNCDIH6DPALHIM5OBQUNKGI',
    'user-agent': 'Mozilla/5.0 ',
    'referer':'https://search.jd.com/Search?keyword=%E6%89%8B%E6%9C%BA&enc=utf-8&wq=sh&pvid=3b1ef19712cf4c78b8dd586f41b432ec'
}

#link="https://club.jd.com/comment/productPageComments.action?callback=fetchJSON_comment98&productId=100006947212&score=0&sortType=5&page=0&pageSize=10&isShadowSku=0&fold=1"
str1='https://club.jd.com/comment/productPageComments.action?callback=fetchJSON_comment98&productId=100006947212&score=0&sortType=5&page='
str2='&pageSize=10&isShadowSku=0&fold=1'
root = "C:\\Users\\92507\\Desktop\\comments.txt"
def linkadd(a):
    return str(a)
def cutword():#分词
    with open(root,encoding='utf-8') as f:
        comments=f.read()
        #comments = re.sub(r"[0-9\s+\.\!\/_,$%^*()?;；:-【】+\"\']+|[+——！，;：。？、~@#￥%……&*（）]+", "", comments)
        for ch in '!"#$%&()*+,-./:;：，！<=>?@[\\]^_‘？{|}【】￥~0123456789。':#去除非法字符
            comments = comments.replace(ch, " ")
        comments=re.sub('[A-Za-z]','',comments)#去除英文字母
        newstring=jieba.cut(comments,cut_all=True)
        wl=' '.join(newstring)
        #print(wl)
        return wl
def getcomments():#获得评论
    if os.path.exists(root):  # 如果存在就清空
        os.remove(root)
    try:

        for j in range(0, 50):
            link = str1 + linkadd(j) + str2
            # print(link)
            r = requests.get(link, headers=kv)
            r.raise_for_status()
            r.encoding = r.apparent_encoding
            r_json = r.text[20:-2]
            r_string = json.loads(r_json)
            r_comments = r_string['comments']
            for i in r_comments:
                with open(root, 'a+', encoding='utf-8') as f:  # a+覆盖写入
                    f.write(i['content'])
            print('第 %d个评论爬取成功' % j)
            time.sleep(random.random() * 5)
    except:
        print("sorry! crawl fail")
#制作词云
def creativewordcloud():
    coloring=np.array(Image.open('girl.png'))
    wordpath='simsun.ttc'
    #配置参数
    wc=WordCloud(width=1000,height=700,background_color='white',max_words=2000,mask=coloring,
                 scale=4,max_font_size=50,random_state=42,font_path=wordpath)
    #生成词云
    wc.generate(cutword())
    #生成图片
    plt.imshow(wc,interpolation="bilinear")
    plt.axis('off')
    plt.figure()
    plt.show()
    wc.to_file('C:\\Users\\92507\\Desktop\\temp.png')

if __name__=='__main__':
    #cutword()
    #creativewordcloud()
    print("this is 京东爬虫！")


```






